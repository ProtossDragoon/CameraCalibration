{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN99HZLk4ZoWluZ9LPnq3NQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProtossDragoon/CameraCalibration/blob/master/CoreML_Tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "313EWEyALGqB",
        "outputId": "0f3f2ce8-8294-4b63-d118-e1e6474ef1a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting coremltools\n",
            "  Downloading coremltools-6.1-cp38-none-manylinux1_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from coremltools) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from coremltools) (21.3)\n",
            "Requirement already satisfied: protobuf<=4.0.0,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from coremltools) (3.19.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from coremltools) (1.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from coremltools) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->coremltools) (3.0.9)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->coremltools) (1.2.1)\n",
            "Installing collected packages: coremltools\n",
            "Successfully installed coremltools-6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install coremltools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# tf.keras를 이용해 MobileNet v2를 다운로드한다.\n",
        "keras_model = tf.keras.applications.MobileNetV2(\n",
        "    weights='imagenet',\n",
        "    input_shape=(224, 224, 3),\n",
        "    classes=1000,\n",
        ")\n",
        "\n",
        "# 클래스 레이블을 다운로드한다.\n",
        "import urllib\n",
        "label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "class_labels = urllib.request.urlopen(label_url).read().splitlines() \n",
        "class_labels = class_labels[1:] # 0번째 인덱스는 'background' 클래스이므로 포함하지 않는다.\n",
        "assert len(class_labels) == 1000\n",
        "\n",
        "# 클래스 레이블이 모두 문자열이 되도록 한 번 더 확인한다.\n",
        "for i, label in enumerate(class_labels):\n",
        "    if isinstance(label, bytes):\n",
        "        class_labels[i] = label.decode(\"utf8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHpvERVkLKXQ",
        "outputId": "0268aafc-5236-424b-c197-ac7220961ea9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:coremltools:Torch version 1.13.0+cu116 has not been tested with coremltools. You may run into unexpected errors. Torch 1.12.1 is the most recent version that has been tested.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14536120/14536120 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import coremltools as ct\n",
        "\n",
        "# 입력 데이터 타입을 이미지로 정의한다.\n",
        "image_input = ct.ImageType(\n",
        "    shape=(1, 224, 224, 3),\n",
        "    bias=[-1, -1, -1], # 픽셀값을 [-1, 1]의 범위로 변환하는 정규화 전처리를 사용한다. mobilenet 모델이 학습될 당시 사용했던 전처리 특성과 동일한 상태로 만들기 위함이다.\n",
        "    scale=1/127\n",
        ")\n",
        "\n",
        "# 클래스 레이블을 설정한다.\n",
        "classifier_config = ct.ClassifierConfig(class_labels)\n",
        "\n",
        "# CoreML 도구가 제공하는 변환 API 를 이용하여 모델을 변환한다.\n",
        "model = ct.convert(\n",
        "    keras_model,\n",
        "    inputs=[image_input],\n",
        "    classifier_config=classifier_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMxb-2ueLg4e",
        "outputId": "22407210-6cf6-4b0e-d3a5-415a27e960c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 6/6 [00:01<00:00,  5.19 passes/s]\n",
            "Converting TF Frontend ==> MIL Ops: 100%|██████████| 426/426 [00:00<00:00, 519.33 ops/s]\n",
            "Running MIL Common passes: 100%|██████████| 39/39 [00:01<00:00, 29.11 passes/s]\n",
            "Running MIL Clean up passes: 100%|██████████| 11/11 [00:00<00:00, 85.54 passes/s]\n",
            "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 487/487 [00:00<00:00, 1298.07 ops/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_spec().description)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6W3DFLJOHSh",
        "outputId": "5be9587d-e058-4d4c-e956-0401f54f8b89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input {\n",
            "  name: \"input_1\"\n",
            "  shortDescription: \"Input image to be classified\"\n",
            "  type {\n",
            "    imageType {\n",
            "      width: 224\n",
            "      height: 224\n",
            "      colorSpace: RGB\n",
            "    }\n",
            "  }\n",
            "}\n",
            "output {\n",
            "  name: \"Identity\"\n",
            "  type {\n",
            "    dictionaryType {\n",
            "      stringKeyType {\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "output {\n",
            "  name: \"classLabel\"\n",
            "  shortDescription: \"Most likely image category\"\n",
            "  type {\n",
            "    stringType {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "predictedFeatureName: \"classLabel\"\n",
            "predictedProbabilitiesName: \"Identity\"\n",
            "metadata {\n",
            "  versionString: \"2.0\"\n",
            "  userDefined {\n",
            "    key: \"com.github.apple.coremltools.source\"\n",
            "    value: \"tensorflow==2.9.2\"\n",
            "  }\n",
            "  userDefined {\n",
            "    key: \"com.github.apple.coremltools.version\"\n",
            "    value: \"6.1\"\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아래 설정한 내용들은 XCode에서 모델에 대한 설명을 표시하는 데 사용된다.\n",
        "\n",
        "# 입출력에 대한 설명을 붙여 준다.\n",
        "model.input_description[\"input_1\"] = \"입력 이미지\"\n",
        "model.output_description[\"classLabel\"] = \"이미지 카테고리\"\n",
        "\n",
        "# 모델 저자 정보를 입력한다. \n",
        "model.author = \"Practical-MLOps\"\n",
        "\n",
        "# 모델의 라이센스 정보를 입력한다.\n",
        "model.license = \"Apache2.0\"\n",
        "\n",
        "# 짧은 설명을 추가한다.\n",
        "model.short_description = \"Practical-MLOps Chapter5\"\n",
        "\n",
        "# 모델의 버전을 설정한다.\n",
        "model.version = \"2.0\""
      ],
      "metadata": {
        "id": "am3Zpk_iNG46"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_spec().description)"
      ],
      "metadata": {
        "id": "JYUgKOr_Xjpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 컴퓨터에 모델을 저장한다.\n",
        "model.save(\"MobileNetV2.mlmodel\")"
      ],
      "metadata": {
        "id": "xAGoDdmHMIJN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M_1T3H5ZTMOf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}